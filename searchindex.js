Search.setIndex({"alltitles": {"Contents:": [[0, null]], "Module contents": [[2, "module-smoothtext"], [3, "module-smoothtext.internal"]], "SmoothText documentation": [[0, null]], "Submodules": [[2, "submodules"], [3, "submodules"]], "smoothtext": [[1, null]], "smoothtext package": [[2, null]], "smoothtext.backend module": [[2, "smoothtext-backend-module"]], "smoothtext.internal package": [[3, null]], "smoothtext.internal.syllabifier module": [[3, "module-smoothtext.internal.syllabifier"]], "smoothtext.internal.tokenizer module": [[3, "module-smoothtext.internal.tokenizer"]], "smoothtext.language module": [[2, "smoothtext-language-module"]], "smoothtext.readability module": [[2, "smoothtext-readability-module"]], "smoothtext.smoothtext module": [[2, "module-smoothtext.smoothtext"]]}, "docnames": ["index", "modules", "smoothtext", "smoothtext.internal"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["index.rst", "modules.rst", "smoothtext.rst", "smoothtext.internal.rst"], "indexentries": {"atesman() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.atesman", false]], "backend (smoothtext.smoothtext.smoothtext property)": [[2, "smoothtext.smoothtext.SmoothText.backend", false]], "bezirci_yilmaz() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.bezirci_yilmaz", false]], "compute_readability() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.compute_readability", false]], "count() (smoothtext.internal.syllabifier.syllabifierbase method)": [[3, "smoothtext.internal.syllabifier.SyllabifierBase.count", false]], "count() (smoothtext.internal.syllabifier.syllabifiereng method)": [[3, "smoothtext.internal.syllabifier.SyllabifierEng.count", false]], "count() (smoothtext.internal.syllabifier.syllabifierpyphenbase method)": [[3, "smoothtext.internal.syllabifier.SyllabifierPyphenBase.count", false]], "count() (smoothtext.internal.syllabifier.syllabifiertur method)": [[3, "smoothtext.internal.syllabifier.SyllabifierTur.count", false]], "count_consonants() (smoothtext.smoothtext.smoothtext static method)": [[2, "smoothtext.smoothtext.SmoothText.count_consonants", false]], "count_sentences() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.count_sentences", false]], "count_syllables() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.count_syllables", false]], "count_vowels() (smoothtext.smoothtext.smoothtext static method)": [[2, "smoothtext.smoothtext.SmoothText.count_vowels", false]], "count_words() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.count_words", false]], "demojize() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.demojize", false]], "flesch_reading_ease() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.flesch_reading_ease", false]], "is_ready() (smoothtext.smoothtext.smoothtext static method)": [[2, "smoothtext.smoothtext.SmoothText.is_ready", false]], "language (smoothtext.smoothtext.smoothtext property)": [[2, "smoothtext.smoothtext.SmoothText.language", false]], "module": [[2, "module-smoothtext", false], [2, "module-smoothtext.smoothtext", false], [3, "module-smoothtext.internal", false], [3, "module-smoothtext.internal.syllabifier", false], [3, "module-smoothtext.internal.tokenizer", false]], "nltktokenizer (class in smoothtext.internal.tokenizer)": [[3, "smoothtext.internal.tokenizer.NLTKTokenizer", false]], "prepare() (smoothtext.smoothtext.smoothtext static method)": [[2, "smoothtext.smoothtext.SmoothText.prepare", false]], "processors() (smoothtext.internal.tokenizer.stanzatokenizer static method)": [[3, "smoothtext.internal.tokenizer.StanzaTokenizer.processors", false]], "reading_aloud_time() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.reading_aloud_time", false]], "reading_time() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.reading_time", false]], "remove_emojis() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.remove_emojis", false]], "sentencize() (smoothtext.internal.tokenizer.nltktokenizer method)": [[3, "smoothtext.internal.tokenizer.NLTKTokenizer.sentencize", false]], "sentencize() (smoothtext.internal.tokenizer.stanzatokenizer method)": [[3, "smoothtext.internal.tokenizer.StanzaTokenizer.sentencize", false]], "sentencize() (smoothtext.internal.tokenizer.tokenizerbase method)": [[3, "smoothtext.internal.tokenizer.TokenizerBase.sentencize", false]], "sentencize() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.sentencize", false]], "silent_reading_time() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.silent_reading_time", false]], "smoothtext": [[2, "module-smoothtext", false]], "smoothtext (class in smoothtext.smoothtext)": [[2, "smoothtext.smoothtext.SmoothText", false]], "smoothtext.internal": [[3, "module-smoothtext.internal", false]], "smoothtext.internal.syllabifier": [[3, "module-smoothtext.internal.syllabifier", false]], "smoothtext.internal.tokenizer": [[3, "module-smoothtext.internal.tokenizer", false]], "smoothtext.smoothtext": [[2, "module-smoothtext.smoothtext", false]], "stanzatokenizer (class in smoothtext.internal.tokenizer)": [[3, "smoothtext.internal.tokenizer.StanzaTokenizer", false]], "syllabifierbase (class in smoothtext.internal.syllabifier)": [[3, "smoothtext.internal.syllabifier.SyllabifierBase", false]], "syllabifiereng (class in smoothtext.internal.syllabifier)": [[3, "smoothtext.internal.syllabifier.SyllabifierEng", false]], "syllabifierger (class in smoothtext.internal.syllabifier)": [[3, "smoothtext.internal.syllabifier.SyllabifierGer", false]], "syllabifierpyphenbase (class in smoothtext.internal.syllabifier)": [[3, "smoothtext.internal.syllabifier.SyllabifierPyphenBase", false]], "syllabifierrus (class in smoothtext.internal.syllabifier)": [[3, "smoothtext.internal.syllabifier.SyllabifierRus", false]], "syllabifiertur (class in smoothtext.internal.syllabifier)": [[3, "smoothtext.internal.syllabifier.SyllabifierTur", false]], "syllabify() (smoothtext.internal.syllabifier.syllabifierbase method)": [[3, "smoothtext.internal.syllabifier.SyllabifierBase.syllabify", false]], "syllabify() (smoothtext.internal.syllabifier.syllabifiereng method)": [[3, "smoothtext.internal.syllabifier.SyllabifierEng.syllabify", false]], "syllabify() (smoothtext.internal.syllabifier.syllabifierpyphenbase method)": [[3, "smoothtext.internal.syllabifier.SyllabifierPyphenBase.syllabify", false]], "syllabify() (smoothtext.internal.syllabifier.syllabifiertur method)": [[3, "smoothtext.internal.syllabifier.SyllabifierTur.syllabify", false]], "syllabify() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.syllabify", false]], "tokenize() (smoothtext.internal.tokenizer.nltktokenizer method)": [[3, "smoothtext.internal.tokenizer.NLTKTokenizer.tokenize", false]], "tokenize() (smoothtext.internal.tokenizer.stanzatokenizer method)": [[3, "smoothtext.internal.tokenizer.StanzaTokenizer.tokenize", false]], "tokenize() (smoothtext.internal.tokenizer.tokenizerbase method)": [[3, "smoothtext.internal.tokenizer.TokenizerBase.tokenize", false]], "tokenize() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.tokenize", false]], "tokenizerbase (class in smoothtext.internal.tokenizer)": [[3, "smoothtext.internal.tokenizer.TokenizerBase", false]], "wiener_sachtextformel() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.wiener_sachtextformel", false]], "wiener_sachtextformel_1() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.wiener_sachtextformel_1", false]], "wiener_sachtextformel_2() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.wiener_sachtextformel_2", false]], "wiener_sachtextformel_3() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.wiener_sachtextformel_3", false]], "wiener_sachtextformel_4() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.wiener_sachtextformel_4", false]], "word_frequencies() (smoothtext.internal.tokenizer.nltktokenizer method)": [[3, "smoothtext.internal.tokenizer.NLTKTokenizer.word_frequencies", false]], "word_frequencies() (smoothtext.internal.tokenizer.stanzatokenizer method)": [[3, "smoothtext.internal.tokenizer.StanzaTokenizer.word_frequencies", false]], "word_frequencies() (smoothtext.internal.tokenizer.tokenizerbase method)": [[3, "smoothtext.internal.tokenizer.TokenizerBase.word_frequencies", false]], "word_frequencies() (smoothtext.smoothtext.smoothtext method)": [[2, "smoothtext.smoothtext.SmoothText.word_frequencies", false]]}, "objects": {"": [[2, 0, 0, "-", "smoothtext"]], "smoothtext": [[3, 0, 0, "-", "internal"], [2, 0, 0, "-", "smoothtext"]], "smoothtext.internal": [[3, 0, 0, "-", "syllabifier"], [3, 0, 0, "-", "tokenizer"]], "smoothtext.internal.syllabifier": [[3, 1, 1, "", "SyllabifierBase"], [3, 1, 1, "", "SyllabifierEng"], [3, 1, 1, "", "SyllabifierGer"], [3, 1, 1, "", "SyllabifierPyphenBase"], [3, 1, 1, "", "SyllabifierRus"], [3, 1, 1, "", "SyllabifierTur"]], "smoothtext.internal.syllabifier.SyllabifierBase": [[3, 2, 1, "", "count"], [3, 2, 1, "", "syllabify"]], "smoothtext.internal.syllabifier.SyllabifierEng": [[3, 2, 1, "", "count"], [3, 2, 1, "", "syllabify"]], "smoothtext.internal.syllabifier.SyllabifierPyphenBase": [[3, 2, 1, "", "count"], [3, 2, 1, "", "syllabify"]], "smoothtext.internal.syllabifier.SyllabifierTur": [[3, 2, 1, "", "count"], [3, 2, 1, "", "syllabify"]], "smoothtext.internal.tokenizer": [[3, 1, 1, "", "NLTKTokenizer"], [3, 1, 1, "", "StanzaTokenizer"], [3, 1, 1, "", "TokenizerBase"]], "smoothtext.internal.tokenizer.NLTKTokenizer": [[3, 2, 1, "", "sentencize"], [3, 2, 1, "", "tokenize"], [3, 2, 1, "", "word_frequencies"]], "smoothtext.internal.tokenizer.StanzaTokenizer": [[3, 2, 1, "", "processors"], [3, 2, 1, "", "sentencize"], [3, 2, 1, "", "tokenize"], [3, 2, 1, "", "word_frequencies"]], "smoothtext.internal.tokenizer.TokenizerBase": [[3, 2, 1, "", "sentencize"], [3, 2, 1, "", "tokenize"], [3, 2, 1, "", "word_frequencies"]], "smoothtext.smoothtext": [[2, 1, 1, "", "SmoothText"]], "smoothtext.smoothtext.SmoothText": [[2, 2, 1, "", "atesman"], [2, 3, 1, "", "backend"], [2, 2, 1, "", "bezirci_yilmaz"], [2, 2, 1, "", "compute_readability"], [2, 2, 1, "", "count_consonants"], [2, 2, 1, "", "count_sentences"], [2, 2, 1, "", "count_syllables"], [2, 2, 1, "", "count_vowels"], [2, 2, 1, "", "count_words"], [2, 2, 1, "", "demojize"], [2, 2, 1, "", "flesch_reading_ease"], [2, 2, 1, "", "is_ready"], [2, 3, 1, "", "language"], [2, 2, 1, "", "prepare"], [2, 2, 1, "", "reading_aloud_time"], [2, 2, 1, "", "reading_time"], [2, 2, 1, "", "remove_emojis"], [2, 2, 1, "", "sentencize"], [2, 2, 1, "", "silent_reading_time"], [2, 2, 1, "", "syllabify"], [2, 2, 1, "", "tokenize"], [2, 2, 1, "", "wiener_sachtextformel"], [2, 2, 1, "", "wiener_sachtextformel_1"], [2, 2, 1, "", "wiener_sachtextformel_2"], [2, 2, 1, "", "wiener_sachtextformel_3"], [2, 2, 1, "", "wiener_sachtextformel_4"], [2, 2, 1, "", "word_frequencies"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property"}, "terms": {"": 2, "0": 2, "1": 2, "100": 2, "11": 2, "12": 2, "14": 2, "15": 2, "183": 2, "2": 2, "200": 2, "238": 2, "29": 2, "3": 2, "30": 2, "4": 2, "42": [], "49": 2, "5": 2, "50": 2, "59": 2, "6": 2, "60": 2, "639": 2, "69": 2, "70": 2, "79": 2, "8": 2, "80": 2, "89": 2, "9": 2, "90": 2, "A": 2, "If": 2, "It": 2, "One": 2, "The": 2, "abstract": 3, "access": 2, "account": 2, "accur": 2, "accuraci": 2, "across": 2, "add": [], "addit": 2, "after": 2, "again": 2, "alia": 2, "all": 2, "allow": 2, "aloud": 2, "alpha2": 2, "alpha3": 2, "alphanumer": 2, "altern": 2, "american": 2, "an": 2, "analysi": 2, "analyz": 2, "ani": 2, "anoth": 2, "api": 2, "ar": 2, "argument": 2, "armi": 2, "art": 2, "ascii": 2, "assess": 2, "atesman": [1, 2], "ate\u015fman": 2, "automated_readability_index": 2, "avail": 2, "averag": 2, "b": 2, "backend": [0, 1, 3], "backend_kwarg": 2, "base": [2, 3], "basic": 2, "basit": 2, "befor": 2, "belong": 2, "between": 2, "bezirci": 2, "bezirci_yilmaz": [1, 2], "bir": 2, "bool": 2, "both": 2, "boundari": 2, "britain": [], "british": 2, "bye": 2, "calcul": 2, "call": 2, "can": 2, "cannot": 2, "capabl": 2, "case": 2, "cat": 2, "charact": 2, "characterist": 2, "check": 2, "class": [2, 3], "classic": 2, "close": 2, "code": 2, "comma": 2, "comparison": 2, "complex": 2, "compute_read": [1, 2], "configur": 2, "consist": 2, "conson": 2, "contain": 2, "content": 1, "convert": 2, "correspond": 2, "count": [2, 3], "count_conson": [1, 2], "count_sent": [1, 2], "count_syl": [1, 2], "count_vowel": [1, 2], "count_word": [1, 2], "countri": 2, "current": 2, "custom": 2, "data": 2, "de": 2, "default": 2, "defin": 2, "delimit": 2, "demoj": [1, 2], "depend": 2, "descript": 2, "design": 2, "detail": [], "detect": 2, "determin": 2, "deutscher": 2, "develop": 2, "dict": [2, 3], "dictionari": 2, "differ": 2, "difficult": 2, "difficulti": 2, "doe": 2, "download": 2, "e": 2, "each": 2, "eas": 2, "easi": 2, "easier": 2, "easiest": 2, "effici": 2, "either": 2, "emoji": 2, "en": 2, "en_u": 2, "eng": 2, "engin": 2, "english": 2, "english_gb": 2, "english_u": 2, "enum": 2, "enumer": 2, "environ": 2, "estim": 2, "etc": 2, "even": 2, "exampl": 2, "expos": 2, "f": 2, "fail": 2, "fairli": 2, "fals": 2, "famili": 2, "first": 2, "flesch": 2, "flesch_kincaid_grad": 2, "flesch_kincaid_grade_simplifi": 2, "flesch_reading_eas": [1, 2], "float": 2, "formula": 2, "forti": [], "found": 2, "fourth": 2, "framework": 2, "freq": 2, "frequenc": 2, "from": 2, "full": 2, "function": 2, "g": 2, "gener": 2, "german": 2, "german_d": 2, "germani": 2, "get": 2, "given": 2, "grade": 2, "great": [], "group": 2, "guarante": 2, "gun": 2, "gunning_fog_index": 2, "handl": 2, "hardest": 2, "have": 2, "hel": 2, "hello": 2, "hi": 2, "higher": 2, "howev": 2, "hyphen": 2, "i": 2, "identif": 2, "identifi": 2, "iki": [], "implement": 2, "import": 2, "includ": 2, "independ": 2, "indic": 2, "initi": 2, "input": 2, "insensit": 2, "instal": 2, "instanc": 2, "int": [2, 3], "interfac": 2, "invalid": 2, "is_readi": [1, 2], "is_support": 2, "iso": 2, "its": 2, "keep": 2, "kincaid": 2, "k\u0131rk": [], "lang": 2, "languag": [0, 1, 3], "lemmat": [2, 3], "length": 2, "letter": 2, "level": 2, "librari": 2, "linguist": 2, "list": [2, 3], "list_support": 2, "lo": 2, "love": 2, "mai": 2, "main": 2, "manag": 2, "map": 2, "mark": 2, "match": 2, "matskovskii": 2, "medium": 2, "method": 2, "metin": 2, "metric": 2, "minut": 2, "model": 2, "modul": [0, 1], "more": 2, "multipl": 2, "must": 2, "name": 2, "narr": 2, "natur": 2, "nearest": 2, "necessari": 2, "need": 2, "nlp": 2, "nltk": 2, "nltktoken": 3, "none": 2, "note": 2, "now": 2, "number": 2, "object": [2, 3], "offer": 2, "one": 2, "onli": 2, "open": 2, "oper": 2, "optim": 2, "option": 2, "order": 2, "organ": 2, "otherwis": 2, "output": 2, "outsid": 2, "packag": [0, 1], "paramet": 2, "parent": 2, "pars": 2, "parse_multipl": 2, "pass": 2, "per": 2, "possibl": 2, "prepar": [1, 2], "present": 2, "print": 2, "process": 2, "processor": 3, "progress": 2, "properli": 2, "properti": 2, "provid": 2, "punctuat": 2, "purpos": 2, "python": 2, "qualnam": 2, "rais": 2, "rang": 2, "read": 2, "readability_formula": 2, "readabilityformula": 2, "readabl": [0, 1], "readi": 2, "reading_aloud_tim": [1, 2], "reading_tim": [1, 2], "recommend": 2, "reduc": 2, "regardless": 2, "region": 2, "remov": 2, "remove_emoji": [1, 2], "replac": 2, "repres": 2, "represent": [], "requir": 2, "research": 2, "resourc": 2, "restructuredtext": [], "result": 2, "retriev": 2, "return": [2, 3], "robert": 2, "round": 2, "round_up": 2, "ru": 2, "rule": 2, "runtimeerror": 2, "russia": 2, "russian": 2, "russian_ru": 2, "sachtextformel": 2, "scientif": 2, "score": 2, "second": 2, "see": [], "sent_token": 2, "sentenc": [1, 2, 3], "separ": 2, "set": 2, "silence_download": 2, "silent": 2, "silent_reading_tim": [1, 2], "simpl": 2, "simplifi": 2, "singl": 2, "skip": 2, "skip_download": 2, "some": 2, "speak": 2, "specif": 2, "specifi": 2, "speed": 2, "split": 2, "split_sent": [2, 3], "st": 2, "standard": 2, "stanford": 2, "stanza": 2, "stanzatoken": 3, "start": 2, "state": 2, "static": [2, 3], "str": [2, 3], "string": 2, "submodul": [0, 1], "suitabl": 2, "support": 2, "supported_backend": 2, "suppress": 2, "switch": 2, "syllabif": 2, "syllabifi": [1, 2], "syllabifierbas": 3, "syllabifiereng": 3, "syllabifierg": 3, "syllabifierpyphenbas": 3, "syllabifierru": 3, "syllabifiertur": 3, "syllabl": 2, "syntax": [], "take": 2, "task": 2, "test": 2, "text": [2, 3], "textbeispiel": 2, "thei": 2, "themselv": 2, "thi": 2, "third": 2, "those": 2, "though": 2, "three": 2, "through": 2, "time": 2, "token": [1, 2], "tokenizerbas": 3, "toolkit": 2, "total": 2, "tr": 2, "true": 2, "tupl": 2, "tur": 2, "turkish": 2, "turkish_tr": 2, "two": 2, "type": [2, 3], "typic": 2, "t\u00fcrkiy": 2, "t\u00fcrk\u00e7e": 2, "u": 2, "underscor": 2, "understand": 2, "unifi": 2, "union": 2, "uniqu": 2, "unit": 2, "up": 2, "us": 2, "user": 2, "util": 2, "valid": 2, "valu": 2, "vari": 2, "variant": 2, "variou": 2, "verbal": [], "verbalize_numb": [], "veri": 2, "verifi": 2, "version": 2, "vowel": 2, "where": 2, "whether": 2, "which": 2, "while": 2, "wiener": 2, "wiener_sachtextformel": [1, 2], "wiener_sachtextformel_1": [1, 2], "wiener_sachtextformel_2": [1, 2], "wiener_sachtextformel_3": [1, 2], "wiener_sachtextformel_4": [1, 2], "without": 2, "word": 2, "word_frequ": [1, 2, 3], "word_syl": 2, "words_per_minut": 2, "world": 2, "wpm": 2, "wrap": 2, "your": [], "y\u0131lmaz": 2, "\u00f6rne\u011fi": 2}, "titles": ["SmoothText documentation", "smoothtext", "smoothtext package", "smoothtext.internal package"], "titleterms": {"backend": 2, "content": [0, 2, 3], "document": 0, "intern": 3, "languag": 2, "modul": [2, 3], "packag": [2, 3], "readabl": 2, "smoothtext": [0, 1, 2, 3], "submodul": [2, 3], "syllabifi": 3, "token": 3}})